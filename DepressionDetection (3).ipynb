{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DepressionDetection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3",
      "language": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEBAxkRZ-eup"
      },
      "source": [
        "# all imports\n",
        "from os import times\n",
        "import tweepy\n",
        "from textblob import TextBlob\n",
        "import pandas as pd\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.corpus import twitter_samples, stopwords\n",
        "from nltk.tag import pos_tag\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import FreqDist, classify, NaiveBayesClassifier\n",
        "import re, string, random\n",
        " "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ki9RKLMd_NjG"
      },
      "source": [
        "## **TWEET EXTRACTION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgAAh0lB-p8R"
      },
      "source": [
        "CONSUMER_KEY='8V4toASRqwVLXtP7yp1pKJICv'\n",
        "CONSUMER_SECRET='TDEVVQ5LBgXGzwXZKne2OAgNapIAeBSCREhLyDwvfZs8RaAO4D'\n",
        "ACCESS_KEY='1312978936037552128-NZ0WXcyfuNzJ98AbxLkuts5TVklx9h'\n",
        "ACCESS_SECRET='qJZ53s1rx6n0UUmIkjxuyXWKigF237qLCxLdPGONOjkcx'\n",
        "auth=tweepy.OAuthHandler(CONSUMER_KEY,CONSUMER_SECRET)\n",
        "auth.set_access_token(ACCESS_KEY,ACCESS_SECRET)\n",
        "auth.secure=True\n",
        "api=tweepy.API(auth,wait_on_rate_limit=True,wait_on_rate_limit_notify=True)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMgHJBoh-tcO"
      },
      "source": [
        "def extraction():\n",
        "\n",
        "    searchQuery = 'Covid 19'\n",
        "    count = 1\n",
        "    try:\n",
        "        # Creation of query method using parameters\n",
        "        tweets = tweepy.Cursor(api.search,q=searchQuery).items(count)\n",
        "        \n",
        "        # Pulling information from tweets iterable object\n",
        "        tweets_list = [[tweet.created_at, tweet.id, tweet.text] for tweet in tweets]\n",
        "    \n",
        "    # Creation of dataframe from tweets list\n",
        "    # Add or remove columns as you remove tweet information\n",
        "        tweets_df = pd.DataFrame(tweets_list)\n",
        "    \n",
        "    except BaseException as e:\n",
        "        print('failed on_status,',str(e))\n",
        "        times.sleep(3)\n",
        "        \n",
        "    q=searchQuery\n",
        "    tweetsPerQry=1\n",
        "    fName='newFile.txt'\n",
        "    sinceId=None\n",
        "    max_id= -1\n",
        "    maxTweets=1\n",
        "    tweetCount=0\n",
        "    print(\"downloading\".format(maxTweets))\n",
        "    with open(fName ,'w') as f:\n",
        "        while tweetCount<maxTweets:\n",
        "            tweets=[]\n",
        "            try:\n",
        "                if(max_id<=0):\n",
        "                    if(not sinceId):\n",
        "                        new_tweets=api.search(q=q,lang=\"en\",count=tweetsPerQry,tweet_mode='extended')\n",
        "                    else:\n",
        "                        new_tweets=api.search(q=q,lang=\"en\",count=tweetsPerQry,since_id=sinceId,tweet_mode='extended')\n",
        "                else:\n",
        "                    if(not sinceId):\n",
        "                        new_tweets=api.search(q=q,lang=\"en\",count=tweetsPerQry,max_id=str(max_id-1),tweet_mode='extended')\n",
        "                    else:\n",
        "                        new_tweets=api.search(q=q,lang=\"en\",count=tweetsPerQry,max_id=str(max_id-1),since_id=sinceId,tweet_mode='extended')\n",
        "        \n",
        "                if not new_tweets:\n",
        "                    print(\"no more tweets found\")\n",
        "                    break\n",
        "                for tweet in new_tweets:\n",
        "                    f.write(str(tweet.full_text.replace('\\n','').encode(\"utf-8\"))+\"\\n\")\n",
        "        \n",
        "                tweetCount+=len(new_tweets)\n",
        "                print(\"Downloaded {0} tweets\".format(tweetCount))\n",
        "                max_id=new_tweets[-1].id\n",
        "        \n",
        "            except tweepy.TweepError as e:\n",
        "                print(\"Some error: \"+str(e))\n",
        "                break\n",
        "        \n",
        "    print (\"Downloaded {0} tweets , saved to {1}\".format(tweetCount,fName)) \n",
        "\n",
        "\n",
        "    f_1 = open(\"newFile.txt\", \"r\")\n",
        "    print(\" The tweet is: \")\n",
        "    read_tweet = f_1.read() \n",
        "    print(read_tweet)                                          \n",
        "\n",
        "    return read_tweet\n",
        "    \n",
        "    "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCpO9TJa_UuV"
      },
      "source": [
        "# **`PREPROCESSING ON TWEETS`**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxoFeUsk_Glc"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize \n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "#from extract_tweets import extraction"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhjiHrrt__2u"
      },
      "source": [
        "# read_tweet1 = extraction()\n",
        "\n",
        "\n",
        "def processing():\n",
        "    text = extraction()\n",
        "\n",
        "    #print(read_tweet1)\n",
        "    # remove url\n",
        "    import re\n",
        "    pattern=r'(?i)\\b((?:[a-z][\\w-]+:(?:/{1,3}|[a-z0-9%])|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))\\)|[^\\s`!()\\[\\]{};:\\'\".,<>?«»“”‘’]))';\n",
        "    match = re.findall(pattern, text)\n",
        "    for m in match:\n",
        "        url = m[0]\n",
        "        text = text.replace(url, '')\n",
        "\n",
        "    # remove mentions\n",
        "    text1 = re.sub('@[^\\s]+','',text)\n",
        "    # text = re.sub(r'^RT[\\s]+', '', text)\n",
        "    t_withoutMentions = re.sub(r'^RT[\\s]+', '', text1)\n",
        "    t3=t_withoutMentions\n",
        "\n",
        "  \n",
        "    #def handle_emojis(t3):\n",
        "        # Smile -- :), : ), :-), (:, ( :, (-:, :')\n",
        "    t3 = re.sub(r'(:\\s?\\)|:-\\)|\\(\\s?:|\\(-:|:\\'\\))', ' Happy ', t3)\n",
        "        # Laugh -- :D, : D, :-D, xD, x-D, XD, X-D\n",
        "    t3 = re.sub(r'(:\\s?D|:-D|x-?D|X-?D)', ' Laugh ', t3)\n",
        "        # Love -- <3, :*\n",
        "    t3 = re.sub(r'(<3|:\\*)', ' Love ', t3)\n",
        "        # Wink -- ;-), ;), ;-D, ;D, (;,  (-;\n",
        "    t3 = re.sub(r'(;-?\\)|;-?D|\\(-?;)', ' Wink ', t3)\n",
        "        # Sad -- :-(, : (, :(, ):, )-:\n",
        "    t3 = re.sub(r'(:\\s?\\(|:-\\(|\\)\\s?:|\\)-:)', ' Sad ', t3)\n",
        "        # Cry -- :,(, :'(, :\"(\n",
        "    t3 = re.sub(r'(:,\\(|:\\'\\(|:\"\\()', ' Cry ', t3)\n",
        "    \n",
        "    phrase= t3\n",
        "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\'t\", \"cannot\", phrase)\n",
        "\n",
        "    # general\n",
        "    phrase = re.sub(r\"n\\'t\", \"not\", phrase)\n",
        "    phrase = re.sub(r\"\\'re\", \"are\", phrase)\n",
        "    phrase = re.sub(r\"\\'s\", \"is\", phrase)\n",
        "    phrase = re.sub(r\"\\'d\", \"would\", phrase)\n",
        "    phrase = re.sub(r\"\\'ll\", \"will\", phrase)\n",
        "    phrase = re.sub(r\"\\'t\", \"not\", phrase)\n",
        "    phrase = re.sub(r\"\\'ve\", \"have\", phrase)\n",
        "    phrase = re.sub(r\"\\'m\", \"am\", phrase)\n",
        "\n",
        "    \n",
        "\n",
        "    #open the fle slang.txt \n",
        "    file=open(\"slang2.txt\",\"r\") \n",
        "    slang=file.read() \n",
        "    ts=phrase\n",
        "    ts=ts.upper()\n",
        "    #seperating each line present in the file \n",
        "    slang=slang.split('\\n') \n",
        "        \n",
        "    tweet_tokens=ts.split() \n",
        "    slang_word=[] \n",
        "    meaning=[] \n",
        "        \n",
        "    #store the slang words and meanings in different lists \n",
        "    for line in slang: \n",
        "        temp=line.split(\"=\") \n",
        "        slang_word.append(temp[0]) \n",
        "        meaning.append(temp[-1]) \n",
        "        \n",
        "    #replace the slang word with meaning \n",
        "    for i,word in enumerate(tweet_tokens): \n",
        "        if word in slang_word: \n",
        "            idx=slang_word.index(word) \n",
        "            tweet_tokens[i]=meaning[idx] \n",
        "\n",
        "    \n",
        "\n",
        "    ts1=\" \".join(tweet_tokens) \n",
        "    phrase1=ts1\n",
        "    phrase1 = re.sub(r\"won\\'t\", \"will not\", phrase1)\n",
        "    phrase1 = re.sub(r\"can\\'t\", \"can not\", phrase1)\n",
        "\n",
        "    # general\n",
        "    phrase1 = re.sub(r\"n\\'t\", \"not\", phrase1)\n",
        "    phrase1 = re.sub(r\"\\'re\", \"are\", phrase1)\n",
        "    phrase1 = re.sub(r\"\\'s\", \"is\", phrase1)\n",
        "    phrase1 = re.sub(r\"\\'d\", \"would\", phrase1)\n",
        "    phrase1 = re.sub(r\"\\'ll\", \"will\", phrase1)\n",
        "    phrase1 = re.sub(r\"\\'t\", \"not\", phrase1)\n",
        "    phrase1 = re.sub(r\"\\'ve\", \"have\", phrase1)\n",
        "    phrase1 = re.sub(r\"\\'m\", \"am\", phrase1)\n",
        "\n",
        "    \n",
        "\n",
        "    punc = '''?@#$%^&*_~'''\n",
        "        \n",
        "    for ele in phrase1:  \n",
        "        if ele in punc:  \n",
        "            phrase1 = phrase1.replace(ele, \" \")  \n",
        "\n",
        "    \n",
        "    # # tokenization\n",
        "    # t10 = word_tokenize(phrase1)\n",
        "   \n",
        "    # def listToString(t10):  \n",
        "            \n",
        "    #     # initialize an empty string \n",
        "    #     t0 = \"\"\n",
        "    #     return (t0.join(t10))           \n",
        "    # t0 = listToString(t10)  \n",
        "    \n",
        "    # # remove puntuations\n",
        "    # punc = '''!()-[]{};:\"\\,<>./?@#$%^&*_~'''\n",
        "    # for ele in t0:  \n",
        "    #     if ele in punc:  \n",
        "    #         t0 = t0.replace(ele, \" \")\n",
        "\n",
        "  \n",
        "    # print (phrase1)\n",
        "    return phrase1\n",
        "\n",
        "\n",
        "# processing()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSORfQje-2z6"
      },
      "source": [
        "def preprocess(phrase1):\n",
        "  processing()\n",
        "  return phrase1"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7uCIyYWAEgG"
      },
      "source": [
        "# **NAIVE BAYES CLASSIFIER**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "gGd9u4AsADeI",
        "outputId": "0a2e0881-36b8-4146-ba3b-26826f40afc9"
      },
      "source": [
        "import pandas as pd\n",
        "#importing the dataset\n",
        "df = pd.read_csv(\"sentiDataSet100.csv\", encoding = \"ISO-8859-1\")\n",
        "df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Learn from DataMuni how to use RAPIDS??s #GPU...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>RT @CongressmanRaja: I??m so proud of our sta...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neutral</td>\n",
              "      <td>RT @chidambara09: #SOciaLmediA\\n\\nhttps://t.co...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neutral</td>\n",
              "      <td>RT @conflictarm: CAR is recruiting two Data An...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>positive</td>\n",
              "      <td>RT @ossia: OK. We're building a Data Science c...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  sentiment  ... Unnamed: 3\n",
              "0   neutral  ...        NaN\n",
              "1  positive  ...        NaN\n",
              "2   neutral  ...        NaN\n",
              "3   neutral  ...        NaN\n",
              "4  positive  ...        NaN\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "jCij57V5AYVn",
        "outputId": "15ad9c7e-fb21-4ae9-f0c8-549428ca03ff"
      },
      "source": [
        "df.groupby('sentiment').describe()\r\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"8\" halign=\"left\">Unnamed: 2</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentiment</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>negative</th>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Unnamed: 2                             \n",
              "               count mean std min 25% 50% 75% max\n",
              "sentiment                                        \n",
              "negative         0.0  NaN NaN NaN NaN NaN NaN NaN\n",
              "neutral          0.0  NaN NaN NaN NaN NaN NaN NaN\n",
              "positive         0.0  NaN NaN NaN NaN NaN NaN NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "NJfXkvBEAdMB",
        "outputId": "fa0599f1-5003-475a-8534-e9cc2b203f33"
      },
      "source": [
        "# ml models understand numbers not text\r\n",
        "df['category']=df['sentiment'].apply(lambda x: 1 if x=='positive' else 0)\r\n",
        "df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Learn from DataMuni how to use RAPIDS??s #GPU...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>RT @CongressmanRaja: I??m so proud of our sta...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neutral</td>\n",
              "      <td>RT @chidambara09: #SOciaLmediA\\n\\nhttps://t.co...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neutral</td>\n",
              "      <td>RT @conflictarm: CAR is recruiting two Data An...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>positive</td>\n",
              "      <td>RT @ossia: OK. We're building a Data Science c...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  sentiment  ... category\n",
              "0   neutral  ...        0\n",
              "1  positive  ...        1\n",
              "2   neutral  ...        0\n",
              "3   neutral  ...        0\n",
              "4  positive  ...        1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnQtAgIyAf4O"
      },
      "source": [
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(df.text,df.category)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBivLo6fAkLf",
        "outputId": "69c63b66-70a8-46aa-f11c-300ec6125f47"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "v = CountVectorizer()\r\n",
        "X_train_count = v.fit_transform(X_train.values)\r\n",
        "X_train_count.toarray()[:2]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 1, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMsjhV1KAl-O",
        "outputId": "6813da27-7581-481d-ac60-1ff34b900dfa"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\r\n",
        "model = MultinomialNB()\r\n",
        "model.fit(X_train_count,y_train)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4czQ-HrApxC",
        "outputId": "67c70fe8-f627-45fd-b36b-9e4aef4f8705"
      },
      "source": [
        "tweet_sample = [\r\n",
        "    'I am really not at all happy'\r\n",
        "    \r\n",
        "]\r\n",
        "tweet_count = v.transform(tweet_sample)\r\n",
        "model.predict(tweet_count)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sp2a2ByBV5AK",
        "outputId": "db8b39e0-a709-410f-e570-6afad19d0092"
      },
      "source": [
        " import nltk\r\n",
        " nltk.download('punkt')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naT0Q5CxVc_0"
      },
      "source": [
        "# def calling():\r\n",
        "#     for counter in range(1):\r\n",
        "#         extraction()\r\n",
        "#         processing()\r\n",
        "#         #naiveclassify()\r\n",
        "#         print(\"======================================================\")\r\n",
        "#         print(\"=====================================================\")\r\n",
        "\r\n",
        "# if __name__ == \"__main__\":\r\n",
        "#     calling()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nq_XS-cAVTl8",
        "outputId": "129a0d73-5415-4f38-f5a6-76dd638a0abc"
      },
      "source": [
        "\r\n",
        "\r\n",
        "tweet_sample = [\r\n",
        "    processing()\r\n",
        "    \r\n",
        "]\r\n",
        "tweet_count = v.transform(tweet_sample)\r\n",
        "model.predict(tweet_count)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading\n",
            "Downloaded 1 tweets\n",
            "Downloaded 1 tweets , saved to newFile.txt\n",
            " The tweet is: \n",
            "b'RT @TheLeadCNN: Tricia Moten, top nurse at a Houston hospital dies of Covid @jaketapper reports https://t.co/PodOp1jCWL https://t.co/ZFq53L\\xe2\\x80\\xa6'\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfZ5UgK7QtKT"
      },
      "source": [
        "###########################\r\n",
        "\r\n",
        "def naive_classifier():\r\n",
        "\r\n",
        "  tweet_sample = [\r\n",
        "      processing()\r\n",
        "      \r\n",
        "  ]\r\n",
        "  \r\n",
        "  tweet_count = v.transform(tweet_sample)\r\n",
        "  print(\"CLASSIFICATION USING NAIVE BAYES\")\r\n",
        "  print(model.predict(tweet_count))\r\n",
        "\r\n",
        "# naive_classifier()"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DucR31FpAskz",
        "outputId": "86b155ce-155a-45ad-c99e-42ab8da906c2"
      },
      "source": [
        "X_test_count = v.transform(X_test)\r\n",
        "model.score(X_test_count, y_test)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7857142857142857"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_yjCMg_rWX2"
      },
      "source": [
        "# **LOGISTIC REGRESSION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGBMrj64zwvC"
      },
      "source": [
        "# libratries for data manupulation and visualization\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import seaborn as sns #plotting library\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import json\r\n",
        "import re\r\n",
        "import string\r\n",
        "import tqdm\r\n",
        "\r\n",
        "import nltk\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from nltk.stem import PorterStemmer\r\n",
        "from nltk.tokenize import TweetTokenizer"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzIxAE37z0m3"
      },
      "source": [
        "sns.set_style('darkgrid') # setting the bg to darkgrid"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHnoC6Fez238"
      },
      "source": [
        "columns = ['sentiment1', 'text', 'date', 'loc']"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJjhnM6vz4X2"
      },
      "source": [
        "df = pd.read_csv('sentiDataSet100.csv', header = None, names = columns,  encoding='ISO-8859-1')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "lz9m_14Qz53d",
        "outputId": "781cc95a-b205-4758-da64-9670d2a879d0"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment1</th>\n",
              "      <th>text</th>\n",
              "      <th>date</th>\n",
              "      <th>loc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sentiment</td>\n",
              "      <td>text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Learn from DataMuni how to use RAPIDS??s #GPU...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>positive</td>\n",
              "      <td>RT @CongressmanRaja: I??m so proud of our sta...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neutral</td>\n",
              "      <td>RT @chidambara09: #SOciaLmediA\\n\\nhttps://t.co...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>neutral</td>\n",
              "      <td>RT @conflictarm: CAR is recruiting two Data An...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  sentiment1                                               text  date  loc\n",
              "0  sentiment                                               text   NaN  NaN\n",
              "1    neutral  Learn from DataMuni how to use RAPIDS??s #GPU...   NaN  NaN\n",
              "2   positive  RT @CongressmanRaja: I??m so proud of our sta...   NaN  NaN\n",
              "3    neutral  RT @chidambara09: #SOciaLmediA\\n\\nhttps://t.co...   NaN  NaN\n",
              "4    neutral  RT @conflictarm: CAR is recruiting two Data An...   NaN  NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "Gp-hmtco0IR4",
        "outputId": "1f279478-cd04-4de5-fe14-486d6b9a6958"
      },
      "source": [
        "# ml models understand numbers not text\r\n",
        "# thus converting sentiment to value (1/0)\r\n",
        "df['category'] = df['sentiment1'].apply(lambda x: 0 if x=='negative' else 1)\r\n",
        "df.head()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment1</th>\n",
              "      <th>text</th>\n",
              "      <th>date</th>\n",
              "      <th>loc</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sentiment</td>\n",
              "      <td>text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Learn from DataMuni how to use RAPIDS??s #GPU...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>positive</td>\n",
              "      <td>RT @CongressmanRaja: I??m so proud of our sta...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neutral</td>\n",
              "      <td>RT @chidambara09: #SOciaLmediA\\n\\nhttps://t.co...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>neutral</td>\n",
              "      <td>RT @conflictarm: CAR is recruiting two Data An...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  sentiment1                                               text  ...  loc category\n",
              "0  sentiment                                               text  ...  NaN        1\n",
              "1    neutral  Learn from DataMuni how to use RAPIDS??s #GPU...  ...  NaN        1\n",
              "2   positive  RT @CongressmanRaja: I??m so proud of our sta...  ...  NaN        1\n",
              "3    neutral  RT @chidambara09: #SOciaLmediA\\n\\nhttps://t.co...  ...  NaN        1\n",
              "4    neutral  RT @conflictarm: CAR is recruiting two Data An...  ...  NaN        1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsHICWC00Jpp",
        "outputId": "959281bc-28c2-4466-e5ae-37e9c2dda2d3"
      },
      "source": [
        "num_tweets = len(df) # total tweets in dataset\r\n",
        "num_pos_tweets = len(df[df['category'] == 1])\r\n",
        "num_neg_tweets = len(df[df['category'] == 0])\r\n",
        "print(\"Total Number of tweets in the dataset = {}\".format(num_tweets))\r\n",
        "print(\"Total Number of positive tweets = {}\".format(num_pos_tweets))\r\n",
        "print(\"Total Number of negative tweets = {}\".format(num_neg_tweets))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Number of tweets in the dataset = 111\n",
            "Total Number of positive tweets = 93\n",
            "Total Number of negative tweets = 18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n313NEHk0Mgz"
      },
      "source": [
        "all_positive_tweets = list(df[df['category'] == 1]['text'])\r\n",
        "all_negative_tweets = list(df[df['category'] == 0]['text'])\r\n",
        "# print(all_negative_tweets[0])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmxYY07V0N54"
      },
      "source": [
        "# if we take the large dataset\r\n",
        "# selecting only a portion of data due large size\r\n",
        "# select_prop = .25\r\n",
        "# all_positive_tweets = all_positive_tweets[:int(len(all_positive_tweets)*select_prop)]\r\n",
        "# all_negative_tweets = all_negative_tweets[:int(len(all_negative_tweets)*select_prop)]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0eeJ0fi0QNj"
      },
      "source": [
        "train_split = 0.8    # ratio to be splitted in\r\n",
        "\r\n",
        "train_pos = all_positive_tweets[:int(len(all_positive_tweets)*train_split)]\r\n",
        "train_neg = all_negative_tweets[:int(len(all_negative_tweets)*train_split)]\r\n",
        "\r\n",
        "test_pos = all_positive_tweets[int(len(all_positive_tweets)*train_split):]\r\n",
        "test_neg = all_negative_tweets[int(len(all_negative_tweets)*train_split):]\r\n",
        "\r\n",
        "train_x = train_pos + train_neg\r\n",
        "test_x = test_pos + test_neg\r\n",
        "\r\n",
        "train_y = np.concatenate((np.ones(len(train_pos)), np.zeros(len(train_neg))))\r\n",
        "test_y = np.concatenate((np.ones(len(test_pos)), np.zeros(len(test_neg))))"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NBPt7050T2W",
        "outputId": "eef74688-afd5-4e22-bd3b-530a9700dc05"
      },
      "source": [
        "print(\"Number of training samples - \", len(train_x))\r\n",
        "print(\"Numner of test samples - \", len(test_x))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training samples -  88\n",
            "Numner of test samples -  23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcIRhTFT0UgO"
      },
      "source": [
        "def process_tweet(tweet):\r\n",
        "    stemmer = PorterStemmer()\r\n",
        "    stopwords_english = stopwords.words('english')\r\n",
        "    # remove stock market tickers like $GE\r\n",
        "    tweet = re.sub(r'\\$\\w*', '', tweet)\r\n",
        "    # remove old style retweet text \"RT\"\r\n",
        "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\r\n",
        "    # remove hyperlinks\r\n",
        "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\r\n",
        "    # remove hashtags\r\n",
        "    # only removing the hash # sign from the word\r\n",
        "    tweet = re.sub(r'#', '', tweet)\r\n",
        "    # tokenize tweets\r\n",
        "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\r\n",
        "                               reduce_len=True)\r\n",
        "    tweet_tokens = tokenizer.tokenize(tweet)\r\n",
        "\r\n",
        "    tweets_clean = []\r\n",
        "    for word in tweet_tokens:\r\n",
        "        if (word not in stopwords_english and  # remove stopwords\r\n",
        "                word not in string.punctuation):  # remove punctuation\r\n",
        "            # tweets_clean.append(word)\r\n",
        "            stem_word = stemmer.stem(word)  # stemming word\r\n",
        "            tweets_clean.append(stem_word)\r\n",
        "\r\n",
        "    return tweets_clean\r\n",
        "# processing()\r\n",
        "\r\n",
        "def build_freqs(tweets, ys):\r\n",
        "\r\n",
        "    yslist = np.squeeze(ys).tolist()\r\n",
        "    freqs = {}\r\n",
        "    for y, tweet in zip(yslist, tweets):\r\n",
        "        for word in process_tweet(tweet):\r\n",
        "            pair = (word, y)\r\n",
        "            if pair in freqs:\r\n",
        "                freqs[pair] += 1\r\n",
        "            else:\r\n",
        "                freqs[pair] = 1\r\n",
        "\r\n",
        "    return freqs"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dX44Q690XrU",
        "outputId": "d4538d34-13e2-4e1b-f428-6cccb8fbf7ed"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0La8Q4q0aoJ"
      },
      "source": [
        "freqs = build_freqs(train_x, train_y)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeXpXYVX0cET"
      },
      "source": [
        "# sigmoid function\r\n",
        "def sigmoid(z):\r\n",
        "    h = 1/(1 + np.exp(-z))\r\n",
        "    return h\r\n",
        "\r\n",
        "#gradient descent algorithm \r\n",
        "def StochasticGradientDescent(x, y, theta, alpha, num_iters, batch_per_itr, batch_size):\r\n",
        "    \r\n",
        "    # x is matrix of features\r\n",
        "    # theta = wt. vector\r\n",
        "    # m = the number of rows in matrix x\r\n",
        "    # J = final cost\r\n",
        "    m =  x.shape[0]\r\n",
        "    loss = []\r\n",
        "    for itr in range(0, num_iters):\r\n",
        "        \r\n",
        "        for i in range(batch_per_itr):\r\n",
        "            batch = np.random.randint(0, m, size=batch_size)\r\n",
        "            x_train = x[batch,:]\r\n",
        "            y_train = y[batch,:]\r\n",
        "            \r\n",
        "            # get z, the dot product of x and theta\r\n",
        "            z = np.dot(x_train, theta)\r\n",
        "        \r\n",
        "            # get the sigmoid of z\r\n",
        "            h = sigmoid(z)\r\n",
        "        \r\n",
        "            # calculate the cost function\r\n",
        "            J = -1/batch_size * (np.dot(np.transpose(y_train),np.log(h)) + np.dot(np.transpose(1 - y_train), np.log(1 - h)))\r\n",
        "            \r\n",
        "            # update the weights theta\r\n",
        "            theta = theta - ( alpha/m * np.dot(np.transpose(x_train), (h - y_train)))\r\n",
        "        if not itr%10 and itr:\r\n",
        "            print(\"Completed {} iterations, loss = {}\".format(itr, np.squeeze(J))) \r\n",
        "        loss.append(J)\r\n",
        "    J = float(J)\r\n",
        "    return J, theta, loss\r\n",
        "\r\n",
        "# extracting features and storing them in matrix\r\n",
        "# 1st feature: no. of +ve words in tweet\r\n",
        "# 2nd: no. of -ve words\r\n",
        "def extract_features(tweet, freqs):\r\n",
        "   \r\n",
        "    word_l = process_tweet(tweet)\r\n",
        "    \r\n",
        "    # 3 elements in the form of a 1 x 3 vector\r\n",
        "    x = np.zeros((1, 3)) \r\n",
        "    \r\n",
        "    #bias term = 1\r\n",
        "    x[0,0] = 1 \r\n",
        "    \r\n",
        "    \r\n",
        "    # loop through each word \r\n",
        "    for word in word_l:\r\n",
        "        pos_pair = (word, 1.0)\r\n",
        "        neg_pair = (word, 0.0)\r\n",
        "        if pos_pair in freqs.keys():\r\n",
        "            # increment the word count for the positive label 1\r\n",
        "            x[0,1] += freqs[pos_pair]\r\n",
        "        if neg_pair in freqs.keys():\r\n",
        "            # increment the word count for the negative label 0\r\n",
        "            x[0,2] += freqs[neg_pair]\r\n",
        "        \r\n",
        "        \r\n",
        "    assert(x.shape == (1, 3))\r\n",
        "    return x\r\n",
        "\r\n",
        "\r\n",
        "def predict_tweet(tweet, freqs, theta):\r\n",
        "    \r\n",
        "    # extract the features of the tweet and store it into x\r\n",
        "    x = extract_features(tweet, freqs)\r\n",
        "    \r\n",
        "    # make the prediction using x and theta\r\n",
        "    y_pred = sigmoid(np.dot(x, theta))\r\n",
        "    \r\n",
        "    \r\n",
        "    return y_pred\r\n",
        "\r\n",
        "\r\n",
        "def test_logistic_regression(test_x, test_y, freqs, theta):\r\n",
        "    \r\n",
        "    # the list for storing predictions\r\n",
        "    y_hat = []\r\n",
        "    m = test_y.shape[0]\r\n",
        "    for tweet in test_x:\r\n",
        "        # get the label prediction for the tweet\r\n",
        "        y_pred = predict_tweet(tweet, freqs, theta)\r\n",
        "        \r\n",
        "        if y_pred > 0.5:\r\n",
        "            # append 1.0 to the list\r\n",
        "            y_hat.append(1)\r\n",
        "        else:\r\n",
        "            # append 0 to the list\r\n",
        "            y_hat.append(0)\r\n",
        "\r\n",
        "   \r\n",
        "   \r\n",
        "    y_hat = np.array(y_hat)\r\n",
        "    y_hat = np.reshape(y_hat, (m, 1))\r\n",
        "    accuracy = np.sum(y_hat == test_y)/m\r\n",
        "    \r\n",
        "    return accuracy\r\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdKfibKg0db3"
      },
      "source": [
        "X = np.zeros((len(train_x), 3))\r\n",
        "for i in range(len(train_x)):\r\n",
        "    X[i, :]= extract_features(train_x[i], freqs)\r\n",
        " \r\n",
        "\r\n",
        "Y = train_y"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbDWf-940gNU"
      },
      "source": [
        "Y = np.reshape(Y, (-1,1))"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qU8TQ87-0hv-"
      },
      "source": [
        "# shuffle data\r\n",
        "s = np.random.permutation(range(len(X)))\r\n",
        "X = X[s]\r\n",
        "Y = Y[s]"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74q9LKNN0jLW",
        "outputId": "bcd1950c-792e-4e27-8659-dd7ffbe1cc5e"
      },
      "source": [
        "J, theta, loss_logs = StochasticGradientDescent(X, Y, theta = np.zeros((3, 1)), alpha=1e-9, num_iters=100, batch_per_itr=50, batch_size=100000) \r\n",
        "print(f\"The cost after traill ning is {J:.8f}.\")\r\n",
        "print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(theta)]}\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Completed 10 iterations, loss = 0.3836000102463794\n",
            "Completed 20 iterations, loss = 0.37570521464560797\n",
            "Completed 30 iterations, loss = 0.37406113769016247\n",
            "Completed 40 iterations, loss = 0.3751947890563034\n",
            "Completed 50 iterations, loss = 0.37197755133549854\n",
            "Completed 60 iterations, loss = 0.36909026635030856\n",
            "Completed 70 iterations, loss = 0.37007581584900284\n",
            "Completed 80 iterations, loss = 0.36876682235182945\n",
            "Completed 90 iterations, loss = 0.3669979986519137\n",
            "The cost after traill ning is 0.36758165.\n",
            "The resulting vector of weights is [0.00016798, 0.01271524, -0.00690057]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "EVLkHBAK0lzo",
        "outputId": "2d3c68b7-d742-449f-ce74-308fb115672b"
      },
      "source": [
        "plt.plot(np.squeeze(loss_logs))\r\n",
        "plt.xlabel(\"Iteration\")\r\n",
        "plt.ylabel(\"Loss\")\r\n",
        "plt.show()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deUBVZf748fdd2eEC4sUFyQVBBdfULLcwJEVyr0nTsUmbsZmWqW/NODVOOWPqr2WGljHNtGzTpl0ptaBCTckdwhRREFy4orLIfpfz+wO9QlwUkSvK/bz+8qz38/Ho/dznec55jkpRFAUhhBDiV9QtHYAQQojrkxQIIYQQDkmBEEII4ZAUCCGEEA5JgRBCCOGQtqUDaC42mw2rtek3ZGk0qqs6/kbkijmDa+YtObuOK81bp9M0uK3VFAirVaGoqLzJxxsMnld1/I3IFXMG18xbcnYdV5p3UJBPg9uki0kIIYRDUiCEEEI4JAVCCCGEQ1IghBBCOCQFQgghhENSIIQQQjgkBUIIIYRDLl8gFEXhy5/zMVttLR2KEEJcV5xaIFJSUoiNjSUmJobly5fX2/7pp59yyy23MH78eMaPH8///vc/+7bPPvuM0aNHM3r0aD777DOnxZh1uox/bsxk6+EzTvsMIYS4ETntSWqr1cqCBQtYtWoVRqORKVOmEB0dTbdu3ersN3bsWObPn19nXVFREa+99hqffPIJKpWKSZMmER0djZ+fX7PHqVGrACirsjT7uYUQ4kbmtBZEWloaoaGhhISEoNfriYuLIykpqVHHbtmyhdtuuw2DwYCfnx+33XYbmzdvdkqc7tqaeUgqzFannF8IIW5UTmtBmEwmgoOD7ctGo5G0tLR6+23atIkdO3bQuXNn5s2bR7t27RweazKZLvl5Go0Kg8HziuO0ni8QVRZbk46/kWk0apfLGVwzb8nZdTRn3i06Wd/tt9/OuHHj0Ov1rFmzhr/85S+sXr26Sedq6mR9VdU1LYeKaqvLTewlk5m5DsnZddwQk/UZjUby8/PtyyaTCaPRWGcff39/9Ho9AFOnTiUjI6PRxzYXN23NX4F0MQkhRF1OKxBRUVHk5OSQl5dHdXU1iYmJREdH19nn1KlT9j8nJyfTtWtXAIYOHcqWLVsoLi6muLiYLVu2MHToUKfEqVGr0GlUVEqBEEKIOpzWxaTVapk/fz6zZ8/GarUyefJkwsLCSEhIIDIyklGjRvHuu++SnJyMRqPBz8+PRYsWAWAwGHjooYeYMmUKAH/84x8xGAzOChV3rUZaEEII8SsqRVFaxSuXzOamjyGMeWM70RFteXJkl2aO6vomfbSuQ3J2HTfEGMSNxF2nlhaEEEL8ihQIarqYZAxCCCHqkgKBtCCEEMIRKRDU3OpaaZbJ+oQQojYpEEgXkxBCOCIFAuliEkIIR6RAAO5aNVXSxSSEEHVIgQDc5EE5IYSoRwoENV1MMgYhhBB1SYGgpoupwmyllTxULoQQzUIKBOCu02BTwGKTAiGEEBdIgeDilN/yLIQQQlwkBYKaLiaASouMQwghxAVSIKjpYgJpQQghRG1SILjYxVRlkQIhhBAXSIGgZqoNkC4mIYSoTQoENc9BgHQxCSFEbVIgkEFqIYRwRAoENVNtgIxBCCFEbVIgkC4mIYRwxKkFIiUlhdjYWGJiYli+fHmD+23cuJHw8HDS09MBMJvN/OUvfyE+Pp4xY8awbNkyZ4YpXUxCCOGA0wqE1WplwYIFrFixgsTERNavX09WVla9/UpLS1m9ejV9+vSxr9uwYQPV1dWsW7eOTz/9lLVr13Ls2DFnhSrPQQghhANOKxBpaWmEhoYSEhKCXq8nLi6OpKSkevslJCQwZ84c3Nzc7OtUKhUVFRVYLBYqKyvR6XR4e3s7K1R5DkIIIRzQOuvEJpOJ4OBg+7LRaCQtLa3OPhkZGeTn5zNy5Ejeeust+/rY2FiSkpIYOnQolZWVzJs3D4PBcMnP02hUGAyeTYpVURQ0ahVo1E0+x41I42L5XuCKeUvOrqM583Zagbgcm83G4sWLWbRoUb1taWlpqNVqNm/eTElJCdOmTePWW28lJCSkwfNZrQpFReVNjsddp6aotOqqznGjMRg8XSrfC1wxb8nZdVxp3kFBPg1uc1qBMBqN5Ofn25dNJhNGo9G+XFZWRmZmJjNnzgSgoKCAuXPnsnTpUtavX8+wYcPQ6XQEBgbSv39/0tPTL1kgrpaHTiNdTEIIUYvTxiCioqLIyckhLy+P6upqEhMTiY6Otm/38fEhNTWV5ORkkpOT6du3L0uXLiUqKop27dqRmpoKQHl5Ofv27aNLly7OChWomW5D7mISQoiLnFYgtFot8+fPZ/bs2YwdO5YxY8YQFhZGQkKCw8Hq2qZPn05ZWRlxcXFMmTKFSZMmERER4axQgZo7meQuJiGEuEiltJL3bJrN1qvqb/zdmr346DUkTIpqxqiub9JH6zokZ9fRnGMQ8iT1eW5aGYMQQojapECc5yFdTEIIUYcUiPPcdTJILYQQtUmBOM9Dp5YWhBBC1CIF4jx3eQ5CCCHqkAJxnnQxCSFEXVIgzpMuJiGEqEsKxHnuOg0Wm4LF1ioeCxFCiKsmBeK8C++EqJJuJiGEAKRA2HnIS4OEEKIOKRDn2d9LLS0IIYQApEDYSQtCCCHqkgJxnpt9DEIKhBBCgBQIO3sLQrqYhBACkAJh53FhDEK6mIQQApACYedmb0FIgRBCCJACYechz0EIIUQdUiDOc5e7mIQQog4pEOfZxyCki0kIIQAnF4iUlBRiY2OJiYlh+fLlDe63ceNGwsPDSU9Pt687cOAA99xzD3FxccTHx1NVVeXMUC9OtWGWLiYhhADQOuvEVquVBQsWsGrVKoxGI1OmTCE6Oppu3brV2a+0tJTVq1fTp08f+zqLxcKTTz7JCy+8QEREBIWFhWi1TgsVADettCCEEKI2p7Ug0tLSCA0NJSQkBL1eT1xcHElJSfX2S0hIYM6cObi5udnXbd26lfDwcCIiIgDw9/dHo9E4K1QAVCoV7lqZ8lsIIS5wWoEwmUwEBwfbl41GIyaTqc4+GRkZ5OfnM3LkyDrrs7OzUalUPPDAA0ycOJE333zTWWHWIS8NEkKIi5zbb3MJNpuNxYsXs2jRonrbrFYru3bt4uOPP8bDw4NZs2YRGRnJkCFDGjyfRqPCYPBscjwajRoPvQZFrb6q89xINBrXybU2V8xbcnYdzZm30wqE0WgkPz/fvmwymTAajfblsrIyMjMzmTlzJgAFBQXMnTuXpUuXEhwczMCBAwkICABg+PDhZGRkXLJAWK0KRUXlTY7XYPBEr1ZRUlZ9Vee5kRgMni6Ta22umLfk7DquNO+gIJ8GtzmtiykqKoqcnBzy8vKorq4mMTGR6Oho+3YfHx9SU1NJTk4mOTmZvn37snTpUqKiohg6dCiZmZlUVFRgsVjYsWNHvcFtZ5AuJiGEuMhpLQitVsv8+fOZPXs2VquVyZMnExYWRkJCApGRkYwaNarBY/38/Jg1axZTpkxBpVIxfPjweuMUzuCuVctdTEIIcZ5KUZRW8RJms9l61V1M09/cToXZxsppfZsxsuuXNMFdh+TsOm6ILqYbkXQxCSHERVIganHXquWFQUIIcZ4UiFrcdWoqZaoNIYQApEDU4abVSAtCCCHOkwJRi9zFJIQQF0mBqMVdVzMGYWsdN3YJIcRVkQJRi5v2wlvlpBUhhBBSIGpxPz/ld5XM6CqEEFIganO3v1VO7mQSQggpELW4a+W91EIIcYEUiFouvFVOxiCEEEIKRB3SxSSEEBdJgahFupiEEOIiKRC1SAtCCCEukgJRizwHIYQQF0mBqMVLX1MgSqssLRyJEEK0PCkQtfh56AAorpQCIYQQUiBqcdOq8dCpKaowt3QoQgjR4qRA/IrBQycFQgghkAJRj5+7juIK6WISQginFoiUlBRiY2OJiYlh+fLlDe63ceNGwsPDSU9Pr7P+xIkT9OvXj7feesuZYdYhLQghhKjhtAJhtVpZsGABK1asIDExkfXr15OVlVVvv9LSUlavXk2fPn3qbVu8eDHDhg1zVogO+XlopUAIIQROLBBpaWmEhoYSEhKCXq8nLi6OpKSkevslJCQwZ84c3Nzc6qz/9ttv6dChA2FhYc4K0SGDh47iSikQQgihddaJTSYTwcHB9mWj0UhaWlqdfTIyMsjPz2fkyJF1upHKysp48803WblyJStXrmzU52k0KgwGzybHq9GoMRg8Mfp7UlplxcvHHZ2mdQ/RXMjZ1bhi3pKz62jOvJ1WIC7HZrOxePFiFi1aVG/ba6+9xm9/+1u8vLwafT6rVaGoqLzJ8RgMnhQVleOuqlnOzS8h0Evf5PPdCC7k7GpcMW/J2XVcad5BQT4NbmtUgSgvL8fd3R21Wk12djZHjhxh+PDh6HS6Bo8xGo3k5+fbl00mE0aj0b5cVlZGZmYmM2fOBKCgoIC5c+eydOlS9u3bx8aNG3nxxRcpKSlBrVbj5ubGfffd15hwr4qfe81fSVGFudUXCCGEuJRGFYj77ruP999/n5KSEh544AEiIyP56quveOmllxo8JioqipycHPLy8jAajSQmJtbZ38fHh9TUVPvyjBkzeOqpp4iKiuKDDz6wr3/11Vfx9PS8JsUBasYgABmoFkK4vEZ1siuKgoeHB5s2beLee+/llVdecXhHUm1arZb58+cze/Zsxo4dy5gxYwgLCyMhIcHhYPX1QqbbEEKIGo1qQSiKwp49e1i3bh0LFy4EasYQLmfEiBGMGDGizrpHH33U4b7vvvuuw/UPP/xwY0JsNtKCEEKIGo1qQfztb39j2bJl3HHHHYSFhZGXl8fgwYOdHVuLuDAGUSwFQgjh4hrVghg0aBCDBg0CaloO/v7+PPPMM04NrKW46zS4a2XCPiGEaFQL4oknnqC0tJTy8nLGjRvH2LFjWbFihbNjazEGD520IIQQLq9RBSIrKwtvb2++/fZbhg8fTlJSEl988YWzY2sxNU9TyyC1EMK1NapAWCwWzGYz3377LdHR0eh0OlQqlbNjazEyH5MQQjSyQNxzzz1ER0dTUVHBwIEDOX78ON7e3s6OrcXIjK5CCNHIQeqZM2fan3gG6NChA6tXr3ZaUC2tZgxCupiEEK6tUQXi3LlzvPbaa+zYsQOouavpj3/8Iz4+Dc/hcSPzc9dxrsqCxWpD28on7BNCiIY0+jkILy8vEhISSEhIwNvbm3nz5jk7thYjT1MLIUQjC0Rubi6PPPIIISEhhISE8Kc//Ym8vDxnx9ZiDB7nH5aT90IIIVxYowqEu7s7O3futC/v2rULd3d3pwXV0vxkug0hhGjcGMRzzz3HU089RWlpKQC+vr4sXrzYqYG1pAvzMclAtRDClTWqQERERPDll1/aC4S3tzdvv/02ERERTg2upciEfUIIcYXvpPb29rY///D22287I57rQu2XBgkhhKtq8j2ciqI0ZxzXlQsT9kkXkxDClTW5QLTmqTagZqC6SO5iEkK4sEuOQfTr189hIVAUhaqqKqcFdT2QGV2FEK7ukgViz5491yqO647BQysFQgjh0mQeiQb4ucuEfUII1yYFogE1M7rKILUQwnU5tUCkpKQQGxtLTEwMy5cvb3C/jRs3Eh4eTnp6OgBbt25l0qRJxMfHM2nSJLZt2+bMMB0yeJyfsM/Weu/WEkKIS2nUg3JNYbVaWbBgAatWrcJoNDJlyhSio6Pp1q1bnf1KS0tZvXo1ffr0sa/z9/dn6dKlGI1GMjMzeeCBB9i8ebOzQnXI7/x8TCWVZgI89df0s4UQ4nrgtBZEWloaoaGhhISEoNfriYuLIykpqd5+CQkJzJkzBzc3N/u6nj17YjQaAQgLC6Oqqorq6mpnheqQTLchhHB1TmtBmEwmgoOD7ctGo5G0tLQ6+2RkZJCfn8/IkSN56623HJ5n48aN9OzZE73+0r/iNRoVBoNnk+PVaNR1ju8QVPPEuOVX61uTX+fsKlwxb8nZdTRn3k4rEJdjs9lYvHgxixYtanCfQ4cO8eKLL7Jy5crLns9qVSgqKm9yPAaDZ53jtRYbAMcKSgkztM6Za3+ds6twxbwlZ9dxpXkHBTX84jendTEZjUby8/PtyyaTyd5tBFBWVkZmZiYzZ84kOjqavXv3MnfuXPtAdX5+Pn/6059YsmQJnTp1claYDbowBiHPQgghXJXTWhBRUVHk5OSQl5eH0WgkMTGRl156yb7dx8eH1NRU+/KMGTN46qmniIqKoqSkhAcffJAnnniCAQMGOCvESwrw1KNWwclzrfuJcSGEaIjTWhBarZb58+cze/Zsxo4dy5gxYwgLCyMhIcHhYHVt7733Hrm5ubz++uuMHz+e8ePHc+bMGWeF6pBeqybE4MGR02XX9HOFEOJ6oVJaybSsZrO1WccgAP66bj+Zp0r59IFBVxvedUn6aF2H5Ow6bogxiNaga6AXx4oqqTBbWzoUIYS45qRAXELXIC8UIPuM6/0KEUIIKRCX0DWw5l7iwzIOIYRwQVIgLqGjwQM3rZosKRBCCBckBeISNGoVnQM8OXJaupiEEK5HCsRldG3jKS0IIYRLkgJxGV3beHG6rFpeHiSEcDlSIC6jaxsvQAaqhRCuRwrEZXSzFwgZhxBCuBYpEJcR5K3Hx03LkTPSghBCuBYpEJehUqlqBqoLpEAIIVyLFIhG6NrGi8Nnymgl01YJIUSjSIFohK5tvCitsmKSqb+FEC5ECkQj2AeqZU4mIYQLkQLRCF3Oz8kk4xBCCFciBaIR/Dx0hBjc2Xu8uKVDEUKIa0YKRCMN7OTP7rxiLFZbS4cihBDXhBSIRhrYyUC52cp+U2lLhyKEENeEFIhGujnEAMCO3MIWjkQIIa4NpxaIlJQUYmNjiYmJYfny5Q3ut3HjRsLDw0lPT7evW7ZsGTExMcTGxrJ582ZnhtkoBk8d3YO82JFb1NKhCCHENeG0AmG1WlmwYAErVqwgMTGR9evXk5WVVW+/0tJSVq9eTZ8+fezrsrKySExMJDExkRUrVvDcc89htbb8e6EHdvIn7UQJlfKOaiGEC3BagUhLSyM0NJSQkBD0ej1xcXEkJSXV2y8hIYE5c+bg5uZmX5eUlERcXBx6vZ6QkBBCQ0NJS0tzVqiNNjDUgNmqsO94SUuHIoQQTue0AmEymQgODrYvG41GTCZTnX0yMjLIz89n5MiRV3xsS+jXwQ+NWsVP0s0khHAB2pb6YJvNxuLFi1m0aFGznE+jUWEweF7F8erLHm8A+oUY2HOi+Ko+63rRmJxbI1fMW3J2Hc2Zt9MKhNFoJD8/375sMpkwGo325bKyMjIzM5k5cyYABQUFzJ07l6VLl172WEesVoWioqZPhWEweDbq+H7tfVixLZfc/GJ83XVN/rzrQWNzbm1cMW/J2XVcad5BQT4NbnNaF1NUVBQ5OTnk5eVRXV1NYmIi0dHR9u0+Pj6kpqaSnJxMcnIyffv2ZenSpURFRREdHU1iYiLV1dXk5eWRk5ND7969nRXqFRnYyR8F2JUnT1ULIVo3p7UgtFot8+fPZ/bs2VitViZPnkxYWBgJCQlERkYyatSoBo8NCwtjzJgxjB07Fo1Gw/z589FoNM4K9YpEtvPBQ6fmx+yz3B7WpqXDEUIIp1EpreQlB2az9Zp0MQHM/+oAm4+c4evf34K77vooXE0hTXDXITm7jhuii6k1i480Ulpl5YesMy0dihBCOI0UiCYYEGKgva8b6zLyL7+zEELcoKRANIFapWJcr2B+OlpEfkllS4cjhBBOIQWiieJ6GVGA9Rkt/wCfEEI4gxSIJmrv587NnQyszzBhax3j/EIIUYcUiKsQ38vI8eJK9hyTZyKEEK2PFIirEB3WBi+9hs/STrZ0KEII0eykQFwFd52Gib3b8c3BAo6edb37rYUQrZsUiKs0Y2BHdBo1K1NzWzoUIYRoVlIgrlKAp56pfduz4ZdT0ooQQrQqUiCawX0317QiVkkrQgjRikiBaAaBXnqm9GnP17+cIrewoqXDEUKIZiEFoplcGItYuiWbVjL/oRDCxUmBaCaBXnruHxzCt5mn+SJd5mgSQtz4pEA0o1mDOjGok4EXkrM4eKq0pcMRQoirIgWiGWnUKv4ZF4Gfh4556/ZTWmVp6ZCEEKLJpEA0swBPPc/H9eBEcSVPfbkf07mqlg5JCCGaRAqEE/Tt6Me8mDDSTpQwddUO3tt5DIvVVm+/g6ZSVmw7KpP9CSGuS1IgnGR8VDvWzhrAgBADCT8cYfaafXW6nIrKzTz++c8s+/EoPx0tbMFIhRDCMSkQTtTBz4OXJ/RiYVwEB06V8uSX+6m22LApCs9tPEhhhRlfdy0f7TnR0qEKIUQ9WmeePCUlhYULF2Kz2Zg6dSoPPvhgne0ffvghH3zwAWq1Gk9PT/75z3/SrVs3zGYzzzzzDPv378disTBhwgR+//vfOzNUp1GpVIyOaIvFpvCPrw/yj68P0MPow5YjZ3kyuitnys2s2p7L8eIKOvh5tHS4Qghh57QWhNVqZcGCBaxYsYLExETWr19PVlZWnX3i4+NZt24dX3zxBbNnz2bRokUAbNiwgerqatatW8enn37K2rVrOXbsmLNCvSbG9jTy6IgufJt5mlc3Z3N7WBum9m3PpN7tUKvg032XnzLcalP47tBpyqut1yBiIYSrc1qBSEtLIzQ0lJCQEPR6PXFxcSQlJdXZx9vb2/7niooKVCoVUPOru6KiAovFQmVlJTqdrs6+N6r7bu7IA7d0olewD38f3R2VSoXRx42RYW34Ij2fSnPDX/yKovDyd4d56sv9/HXdfiw2GdgWQjiX07qYTCYTwcHB9mWj0UhaWlq9/d5//31WrVqF2WzmnXfeASA2NpakpCSGDh1KZWUl8+bNw2AwXPLzNBoVBoNnk+PVaNRXdXxj/TWuZ7119w/tQtLKn9iSV8yU/h0dHrdyazYf7T3BwJv82ZZTyGtbj/KPcT3sRbUxbDYFlQr7Mdcq5+uNK+YtObuO5szbqWMQjTF9+nSmT5/OunXrWLp0KUuWLCEtLQ21Ws3mzZspKSlh2rRp3HrrrYSEhDR4HqtVoaio6dNtGwyeV3X81ehucKNLoCdvphyhvKwai82GSqUixOBBlzae7D1WzOINBxnVvQ3Pj+vBqynZvPdTLsFeOn7Tv0OjPqO82spD/0ujjZeeF8b3RKVStWjOLckV85acXceV5h0U5NPgNqcVCKPRSH7+xTmJTCYTRqOxwf3j4uJ49tlnAVi/fj3Dhg1Dp9MRGBhI//79SU9Pv2SBuJGpVCqmDejAvzYd4p+bMh3uE9XOl2fvDEetUvHw8M4cK6rg398fJut0GSO7BTKwkz9uWsc9hoqi8NyGg2TknwNg3c8m7ooKdrhvY2zPOcvz3xzimdHdGRTqX2dblcXWYBxCiBuL0/4nR0VFkZOTQ15eHtXV1SQmJhIdHV1nn5ycHPufv//+e0JDQwFo164dqampAJSXl7Nv3z66dOnirFCvC3dFBrNuziDWzRnE178fzJdzBvHa5Cj+PLILD9zSiZcn9MJdpwFArVKxYGwEY3oa+fZgAX/+LIOY//7IV/tNDs/91vZckg+d5pHhnenX0Y9//3CYgtKmPeFtUxReScnmZEkVj3+ewfacs0BNYXj5u8MMf2VLk57rsFhtPPXlfl5NyW5SXA0xnati4aZM8ksqr/pcx4oqKCo3N0NUQtwYnNaC0Gq1zJ8/n9mzZ2O1Wpk8eTJhYWEkJCQQGRnJqFGjeO+999i2bRtarRZfX1+WLFkC1HQ7zZs3j7i4OBRFYdKkSURERDgr1OuCSqUi2Ne9zrp2vu4Mvsnf4f4eOg3P3hlO9R1h7MwrYuX2XBZuyqRLoCcRxotNxh+yTrPsx6OM7dmW+27uyIhubZi2ehdLvs3izd/efMVxfnfoNIcKynj89q6s+zmfJz7P4NERXfhk30mOnClHq1bx5c/59VoWl/P6lhy+O3QagCE3+XNzp0uPOTXWuzvy+Dw9n515Rbxxdx+MPm5NOo+iKPx+7T4MHjremd4PrUZaSaL1Uymt5OUFZrP1hh2DaA6F5dXc9+5utBo1797XDx83LZ/sO8lL3x2me1tvlt3d294CeXdHHq+kZPPvqX0Y2smv0Z9htSncu3oXKPDhbwdwrsrCnz5O5+CpUgK99MyP7c53h06z8cApNs0dYv+8y/kh6zT/98V+xkcGszOvCI1axQczB1x1V1WF2cqYN7bTtY0Xh0+XEeCp4427+9A9xP+Kr/WRM2Xc8/YuAH5/ayizh4ReVWzX2o3+77spXDFnaN4xCPkZ1Er4e+pZHN+TU+eq+MfXB3luYyZLkrIYHOrPq5Mj63xZTxvQkV7BPjzz5c9k1pqWXFEUXtuczdyP9lHh4JbbpMwCss+UM+fWUDRqFQYPHf+dWtMNtmbmAG7tHMDoiCAqzDa2Zp9tVNzHiip4dsNBehi9eWpUN+bdEUZuYQUrm+H1rRt+OUVZtZVHhnfm1clRnC03M/d/aZwsrtvdVFZt4dWUbHLONPyfasfRIgD6d/Tjre25ZBWUXXV8QlzvpEC0IlHtfXlsRBe2HDnLVxkmHhwSyssTe+Hrrquzn0atYsldPfF20/LYZz+TX1KJoii89N1h3vkpj515xSxJqvtQo9WmsPzHo3Rt48mo7m3s633ddUwb0BGDZ81n9O9oIMBTx6YDBQ3GabHa2JVXxKspR/jDR2moULEovgd6rZrBN/kztmdb3vkpj6zT9b+EC8urGzWeoCgKH+89QViQF73b+xLV3pdXJkdxpqyae1dsJ+/8q2GLK8z88X/prN6Rx1/X10yF4siO3CLa+7mzOL4HPm5aFmw8eF08i/Lx3hMcKpB3jwjnaPHbXEXzurtfe6yKQtdArwbHLwCMPm68NeNm7nlzO49++jP9Ovrxyb6TTBvQAU+dhhXbcxnQ0Y/4yGCqLDZeTTnC0cIKltzVE/Ulnr3QqFXEhAfxeXo+pVUWvN20KIrChgOn2J1XzKGCMg6fLqPSYkOrVtGvox9zhoTWmWbksRFd2HrkLDPf2014W296BfugVqnYmVfEofO/3KPa+XBnj2q1n5UAABkuSURBVLZEh7WhjXf9cYX0k+fILChj3h3d7M999G7vy9K7e/Popz8ze81enhsTzn9+OEJeYQUzbu7IuzuPsezHozw8vHOdc1ltCruOFTEqLAh/T31NS2f9L7y/8xi/HdRyd9adKK5kSVIWA0L8eOPuPld1LpuiUGG24qW/sb4Sqi02cs6W073tjf8g7fXoxvrXIC6r5pZZxw/b/Vp4sA8vjO/JI5/8zJEz5Uwf0JFHR3TGpsDe4zWtCDetmpWpuRw+Xc6UPu0Y2S3wsueNCQ9i7Z4TpBw+w9ieRt7YmsPK1Dz83LWEBXkxPiqY/iEGBnUy4O1W/5+gv6eepXf35uv9p/j5ZAmfn3+Fa+/2vjw09CbUKhUbD5ziheTDvJB8mEAvPd3aeNIz2IdxvYLp5O/Bx3tP4KXXcGePurdW9zD68OHswcxc+RMPf/Iz7lo1/54YyaBQf0qqLLy3M4/hXQPo0+Hi2MyBU6WUVlkZeH7g/I7wIBL3m1i9I4+pfdvjqW/cWEtTHSooZfG3WTw6ogu92/va1yefH9TflVfMoYJSwoIu/yX5RfpJfjGVMmdIKIFeegBOllTy9PoDZJ8tY9W0ftwU0HIPl6UeLaS82srtYW0uu6/ZauOJzzPYfrSQhXERjI5oew0idC0ySH2eKw5oXch565GzHCuq4O5+7e2/tk+XVTN99S7OlpsJ9NLz99ju3NY5oFHntSkK49/8iW5BXvTv6McrKdmMjwrm6ZiwK3ry+wKLTUFRFHS/unMoq6CM1KOFZJ2uaZVkFpRhtSkMDjWw+1gxE6Pa8eSobg7z/iX3LK9vzubufh3sX7pl1RamvbML9flBco/z4zZvp+by+pYcNvzhFvuXatqJEh74cC9P3N610Q8rOpKcWcB7O4/x/Lge9e5iA9h3vJjHPvuZ0iorw7oE8PLESPu2332wl+JKM6ZzVYzp0ZanR3dv8HMMBk8OHy9iwoqfqLTY8HHT8qdhNxHgqeefmzKx2hS0ahVtvPWsmtbPnvv7O4/xyb4TvD61N+0cxAc13XmHT5fTpY3nJVuXtRVVmPF206JVX9w/7UQJf/hoH1abwn+n9mZASMN3slltCs8kHuDbzALa+7pRVGHhnfvqFjdX/D8NzTtIrXn2wtNpNzibTaGysun3qLu7667q+BvRhZw7+XsQ2c63zpe3p15D3w5+eLlpWBjXg+6N+HV6gUql4nRpNV/tN7H9aBF3dA/iH3eGo1ZfeXGAmuc+NA6ODfDS07u9LyO7tWFi73ZMiArGx13LtuxCys025seG4++pq3ecu7sOnaIQ3T2ozm2veo2a7m29+XDXcUqrrNzWpaYgvrntKO46NTMHXuxOMvq4kXq0kJ+OFjK1XweHX4znKi18f+g0H+09zn9+OMLqn/LoaPCwf4klZRbw9PpfyD9XTUmlmZG/+tX8Y/ZZ/vxZBkHebgzrGkjyodPcFRmMt5sW07kq/vPDEaYN6IjR140Nv5xicp92Dd455u6u499Jh0g/UcKLE3pxoqSSj/ae5JuDBXQJ9OS1Kb0Z2MnAB7uOYzpXxchugby+JYdlPx6lpNJCSZWFkd3q/6pXFIX/bsnh718dQK1SNfilbrUpfLz3JG9tP8orKUd4Y+tRvj1YQP8QAwGeekznqvjjx+kYPHT4eejYeKCAMT3a1mmdVZqt2BRQgBeSskjcb+KR4Z15dEQXvvzZxI/ZZxnXy2i/BdkV/0/Dleft5dXwrd9SIM5zxX9Ml8vZ6OPGkJsCGn27am0GTx2f7DvJrZ39WRTf45o8N+Cp19K/o4F7+ndgYu9gOhgcT59+qbzb+7lTUmXhoz0nGBDiR6CXnv+XnEV0WBtu/VULys9dy6dp+XQJ9KRrGy/7+uwz5Sz7MYdnvz7IpoMF5BVWEGH0xmJTWLP7OGfLqzlXZWH+Vwfo1c6XYV0C+PJnE8O7BdLmfAtlR24hf/4sgy6BXiy9uzdR7XxZs/sEPm5a+ocYSMww8WNOIX8Z1Y0ewd58tOcEBg9dna6x2s5WWpj3xc/E9QxmxsAQ4noa6WjwILytN3+PDSfAS0/H839fa/acYHtOEZsOFjCpdzv6dfTjs30nub17GwI89fZzKorCf344wrs7jxHgqWNHbhFje7at121YUFrF/32RwcfnZyzu3cGPmPAgdh8r5n97T+DvqeOVlCOcKavm9Sm9GdW9DR/tPcEv+ee4s0dbtucUMv/rAyxJymJlai5vbc/lF1Mpvx0UwpwhoXi7aeke5MUHu45zqrSaEV0DUalULvl/Gpq3QMgYhHCK8LbefDCzP6H+nvW6hpxNq1YR5GDgurEeGnoTW46c4V+bMnni9q5UWWwM7FR/wH9Y10A6+Xvw3s5jxIQHUVhh5sXkw3xzsAC9RkVsRFsm9m5Hz2AfNGoV1RYbb2zN4d2dx/hk30l6t/fllcmR2GzwzcECXkvJ5tUpUeQVVvDXdb/Qyd+DN+7ujbeblgBPGBxq4Iv0fO4f3ImkQ6fpEujJTYE1rZH+Hf34eO8Jpg3o6LC19fr3hwGYPaQTUNPKG9uz/tQ3DwzpRNrJErbnFPK7wSH84babKK608EV6Pv/dnG3v4rLaamYX/mjvCe7p155pAzpy99s7eTUlm4XjetjPt/XIWZ7dcJBKs5X5sd0Z18tob6neFRXMM4m/8Pw3h1ABL07oZS+0/3d7VxZ+c4hJb/3EiZIqgn3cmDOkEzqNGotNIdjHjXG9LsZ/y00BPHBLJ1Zsz8XPXcejI+reaCCaRloQ57nirw1n5xzopXf4ZdXSLpe3TqOme9uaX6SpR4uottr46x1h6H/14J5apUKnVvFZej5VFhv/2pjJodNl3D+4E8+P68GdPYwYfdzs3U8atYrBN/nTt4MvPm5a/h7bHW83LW5aNVqNio/3naRrG0+e/+YQlWYrS+/uXecOLTetms/T82nv585He04wuU87+xPnXnoNn6Xn08HgTliQV53uwtzCChZsOMjkPu0uO5CrUqm4PawNt3UOYFxkcM0vcZ0GBfhk30kGdTJQbVV48osMkg+dZvqAjvx5ZBd83XWYrTb+t+8kAzsZCPLS89rmbP5fchYh/h68PqU3g2/yr9eNOaaHEU+9htiItnViC2/rTUFpNceLK/nTsM7MvzOcQaH+9Ovox4AQA+FtveuNZ/UP8aOkwsKaPcc5da6aUT2NVNd6ze/Z8mq+O3SaL382YfDQXdWPCGc5fLqMV1Oy6dbGq97t6RdYbAoLN2VyqrSaXsH1xw+aswUhg9TnueKAlivmDI3P+4WkLD7ae4JewT68Pb2fw30qzVbuevMnCivMRLXz4e+x4XQOvPK7gKotNqa+vZOTxZWo1SpemxxVb7oRs9XGuOWpVJptlJutfDhzAN2Can5xW2wK97y9k9zCCroEejKulxF/Tx3780vZnnOW02VmPn1goL0L60pVmq1MfGsHblo1p8uq0WvUPHF7V8b2bGv/oq4wW5mycgd+HjrctRrST5YwpU87HhvZ9ZpN4KgoCm/8eJSV23MZ2T2IEF83TpZUcrSwwn6LtFpVU6z/Mqob46PaXZO4LsdqU/hg1zHe2JpDtVVhYu9g/hbj+KaDN388yvJtR4GaW8Kn31z3rkUZpHZAWhBXzhVzhsbn3a+jH6lHCxnT00hkO1+H+2g1aroFedGvox9PRncjoIlfwBq1irbeepIyT/NkdDfuCA9yuE9RhZmdecV08vfgD7eF2r+c1SoVcT2NtPdzJ+dMOesyTPyQdYacM+XcFOjJ/40OJ7xN029f1WrUeOk1fLX/FLeE+pMwKZJ+Hf3q/IrXadQEeev5396TlFVbWDAmgpmDQurcqeRsKpWKgZ0MeOk1/G/vCfbnn6PKqmD0cSO+VzCPjOjMH267iV/yS/lw9wlOl1UxONS/SS3djPxzHDpVRid/x2NdZquNVam5vLntKEM7B9YZyyuqMLMyNZekzNMkZ55mVWouiftPMaxrIDcFeJKSdZZ7+nWo1z2773gxz208yOiIIDoHePLB7uN4u2mIqnX7s7QgHJAWxJVzxZzh+s67qMKMwcNx1wJAXmEFk1fuYNbgEB4a2nA/e15hBWabjVB/z5ppUZohZ0VROHq2gtAAjwZvV1YUhcT9Jvp28LMPercUN083KsoqHd5hZrUpvLE1h7d/yqNzgCfPxHav84zJ5RwqKGX2h/uostp4f0b/OjcpQE3x+NfGTLJOl6FWwZCbAnh5Yi/UKhUWq42HP0ln97FiDB46tGoVXm5aZg0KYUyPtqSdKGH2mn38PbY7d0VenJb/XKWF6e/uQq1S8d6M/rhr1Tzz1QGSMk/XeQ6kOVsQUiDOu56/NJzFFXOGGz/vX0zn6BzgeUV3l93oOTdFY3L+Mbvm3SanzlVxT/8O/HZQyGW74c6UVTPr/T1YFYVqi40ugZ4su6ePvWiu3X2cl7+veYDzL6PCMJ2r4oXkLB4e1pmZg0J4MTmLtXtO8NyYcIc3CiiKwtRVOzF46Fhxb1/7uqcTD5CcWcCKe/vaW7QWq41XN2cT1c7X3uq8IV4YJIRwjh7Ghv9Diytza+cA1s4awOubc1iz+zhrdh+nna8bke18CTG44+ehw+Cho623G538PfB11/LkFxkUVZh58zd9OHiqlH9tOsT6DBPxkcEkZph48bvDjOgayLNjwu1Tzew+VsR/t2RTUFbN2j0nmDagg8PiADXdZOOjgnklJZvsM+V0DvTkvZ3H+OZgAQ8NvalOd6dWo+bPI7s67e9HCoQQwqV56bU8NaobE3sHsyO3iPQT50g/UUJSZgG/no9Ro1ZhtSksuasnEUYfurf1Zt3PJhJ+OIICPL8pk0GdDDw/rof9rjeVSsUzo7tzwFTKmt3HGdTJwMPDL/0CtLheRl7fksMX6fkMCPHj1ZRs7uje5prP/SVdTOdJE9x1uGLekvOVsykK5yotFFWYyT9XRV5hBbmFFfRu71vnJoKsgjLue283VptCr2Af/ju1t8P5uQ4V1BSIh4d3ueQ40wVPfbmfXXlFWKwKoQEeLL+nT6O6FaWLSQghnEytUuF3fuqP0ABPBjfwlsRuQV7Mva3m4coXxvdqcPLGsKCap9Yba3xUMN8dOk0bLz0vju/VpBkNrpYUCCGEuEq/HRTS7N0/t4T68+CtoYzoGkjbJr4q92pJgRBCiOuQRq1iTgu/2lbeKCeEEMIhpxaIlJQUYmNjiYmJYfny5fW2f/jhh8THxzN+/HjuvfdesrIuvubywIED3HPPPcTFxREfH09VVZUzQxVCCPErTutislqtLFiwgFWrVmE0GpkyZQrR0dF063bxBS7x8fHce++9ACQlJbFo0SLeeustLBYLTz75JC+88AIREREUFhai1UpvmBBCXEtOa0GkpaURGhpKSEgIer2euLg4kpKS6uzj7X3xJTQVFRX2JxG3bt1KeHg4ERERAPj7+6PRXPsRfCGEcGVO+1luMpkIDr44j4jRaCQtLa3efu+//z6rVq3CbDbzzjvvAJCdnY1KpeKBBx7g7NmzjB07ljlz5lzy8zSamvlmmkqjUV/V8TciV8wZXDNvydl1NGfeLd5vM336dKZPn866detYunQpS5YswWq1smvXLj7++GM8PDyYNWsWkZGRDBkypMHzWK2KPCh3hVwxZ3DNvCVn19GcD8o5rYvJaDSSn59vXzaZTBiNjuceAYiLi+Pbb78FIDg4mIEDBxIQEICHhwfDhw8nIyPDWaEKIYRwwGkFIioqipycHPLy8qiuriYxMZHo6Og6++Tk5Nj//P333xMaWnPP79ChQ8nMzKSiogKLxcKOHTvqDG4LIYRwPqd1MWm1WubPn8/s2bOxWq1MnjyZsLAwEhISiIyMZNSoUbz33nts27YNrVaLr68vS5YsAcDPz49Zs2YxZcoUVCoVw4cPZ+TIkZf8PJ1Oc8mmUmNc7fE3IlfMGVwzb8nZdTRX3q1msj4hhBDNS56kFkII4ZAUCCGEEA5JgRBCCOGQFAghhBAOSYEQQgjhkBQIIYQQDrl8gbjclOStwcmTJ5kxYwZjx44lLi7OPudVUVER999/P6NHj+b++++nuLi4hSN1DqvVyoQJE/j9738PQF5eHlOnTiUmJobHHnuM6urqFo6weZWUlPDII49w5513MmbMGPbs2eMS1/rtt98mLi6OcePG8fjjj1NVVdUqr/W8efMYMmQI48aNs69r6PoqisK//vUvYmJiiI+Pv+IZKVy6QFyYknzFihUkJiayfv36Ou+kaC00Gg1//etf+eqrr1i7di0ffPABWVlZLF++nCFDhrBp0yaGDBnSagvk6tWr6dq1q335xRdfZNasWXzzzTf4+vry8ccft2B0zW/hwoUMGzaMDRs28MUXX9C1a9dWf61NJhOrV6/mk08+Yf369VitVhITE1vltZ40aRIrVqyos66h65uSkkJOTg6bNm3in//8J88+++wVfZZLF4jGTEneGrRt25ZevXoBNVOsd+nSBZPJRFJSEhMmTABgwoQJ9rmwWpP8/Hy+//57pkyZAtT8otq+fTuxsbEATJw4sVVd83PnzrFjxw57vnq9Hl9fX5e41larlcrKSiwWC5WVlQQFBbXKaz1w4ED8/PzqrGvo+l5Yr1Kp6Nu3LyUlJZw6darRn+XSBcLRlOQmk6kFI3K+Y8eO8csvv9CnTx/OnDlD27ZtAQgKCuLMmTMtHF3ze/7553nyySdRq2v+qRcWFuLr62t/AVVwcHCruubHjh0jICCAefPmMWHCBJ5++mnKy8tb/bU2Go387ne/4/bbb2fo0KF4e3vTq1evVn2ta2vo+v76O+5K/w5cukC4mrKyMh555BH+9re/1XlZE4BKpbK/sKm1+O677wgICCAyMrKlQ7lmLBYL+/fv59577+Xzzz/Hw8OjXndSa7zWxcXFJCUlkZSUxObNm6moqGDz5s0tHVaLaM7r2+Lvg2hJVzol+Y3MbDbzyCOPEB8fz+jRowEIDAzk1KlTtG3bllOnThEQENDCUTav3bt3k5ycTEpKClVVVZSWlrJw4UJKSkqwWCxotVry8/Nb1TUPDg4mODiYPn36AHDnnXeyfPnyVn+tf/zxRzp27GjPa/To0ezevbtVX+vaGrq+v/6Ou9K/A5duQTRmSvLWQFEUnn76abp06cL9999vXx8dHc3nn38OwOeff86oUaNaKkSneOKJJ0hJSSE5OZmXX36ZW265hZdeeonBgwezceNGAD777LNWdc2DgoIIDg7myJEjAGzbto2uXbu2+mvdvn179u3bR0VFBYqisG3bNrp169aqr3VtDV3fC+sVRWHv3r34+PjYu6Iaw+Vnc/3hhx94/vnn7VOSz507t6VDanY7d+5k+vTpdO/e3d4X//jjj9O7d28ee+wxTp48Sfv27fnPf/6DwWBo4WidIzU1lZUrV7Js2TLy8vL485//THFxMT169ODFF19Er9e3dIjN5pdffuHpp5/GbDYTEhLCokWLsNlsrf5av/LKK3z11VdotVp69OjBwoULMZlMre5aP/744/z0008UFhYSGBjIww8/zB133OHw+iqKwoIFC9i8eTMeHh48//zzREVFNfqzXL5ACCGEcMylu5iEEEI0TAqEEEIIh6RACCGEcEgKhBBCCIekQAghhHBICoQQDvTr1w+ombpi3bp1zXruN954o87yb37zm2Y9vxDNRQqEEJdw/Phx1q9ff0XHWCyWS25ftmxZneU1a9ZccVxCXAtSIIS4hJdeeomdO3cyfvx43n77baxWK0uWLGHy5MnEx8fbv9xTU1OZNm0af/jDH4iLiwPgoYceYtKkScTFxbF27VqgZqrxyspKxo8fzxNPPAFcbK0oisKSJUsYN24c8fHxfPXVV/Zzz5gxw/6OhyeeeAJ5fElcE4oQop6+ffsqiqIo27dvVx588EH7+jVr1iivv/66oiiKUlVVpUycOFHJzc1Vtm/frvTp00fJzc2171tYWKgoiqJUVFQocXFxytmzZ+uc+9eftWHDBmXWrFmKxWJRCgoKlBEjRigmk0nZvn270r9/f+XkyZOK1WpV7r77bmXHjh3OS16I81x6sj4hrtTWrVs5ePCgfX6fc+fOcfToUXQ6HVFRUYSEhNj3fffdd/nmm2+Amrf6HT16FH9//wbPvWvXLuLi4tBoNLRp04aBAweSnp6Ot7c3vXv3tk/bHBERwfHjx7n55pudmKkQLj6bqxBXSlEUnnnmGYYNG1ZnfWpqKp6ennWWf/zxR9auXYuHhwczZsygqqqqyZ9be/4gjUaD1Wpt8rmEaCwZgxDiEry8vCgrK7MvDx06lA8//BCz2QxAdnY25eXl9Y47d+4cfn5+eHh4cPjwYfbu3WvfptVq7cfXdvPNN/P1119jtVo5e/YsO3fupHfv3k7ISojGkRaEEJcQHh6OWq3mrrvuYtKkScycOZPjx48zadIkFEXB39+f//73v/WOGz58OGvWrGHMmDF07tyZvn372rfdfffd3HXXXfTs2ZOXXnrJvj4mJoY9e/Ywfvx4VCoVTz75JEFBQfapu4W41mQ2VyGEEA5JF5MQQgiHpEAIIYRwSAqEEEIIh6RACCGEcEgKhBBCCIekQAghhHBICoQQQgiH/j/LG5MVDmDmNQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fesrudzz0oC3",
        "outputId": "431457ef-3f7e-440c-c794-886e7df8e4da"
      },
      "source": [
        "tmp_accuracy = test_logistic_regression(test_x, np.reshape(test_y, (-1,1)), freqs, theta)\r\n",
        "print(tmp_accuracy)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9130434782608695\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiDiwoKT0qPT",
        "outputId": "fc04f48c-9e1f-46f0-f56c-5e3823ae1e0e"
      },
      "source": [
        "# example\r\n",
        "my_tweet = 'This is a ridiculously bright movie. The plot was terrible and I was sad until the ending!'\r\n",
        "print(process_tweet(my_tweet))\r\n",
        "y_hat = predict_tweet(my_tweet, freqs, theta)\r\n",
        "print(y_hat)\r\n",
        "if y_hat > 0.5:\r\n",
        "    print('Positive sentiment')\r\n",
        "else: \r\n",
        "    print('Negative sentiment')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ridicul', 'bright', 'movi', 'plot', 'terribl', 'sad', 'end']\n",
            "[[0.49831686]]\n",
            "Negative sentiment\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGG_DMb41IZm",
        "outputId": "0572ccb0-7b46-41e2-9dc6-d7f0c0c6e4bd"
      },
      "source": [
        "my_tweet =  processing()\r\n",
        "print(my_tweet)\r\n",
        "y_hat = predict_tweet(my_tweet, freqs, theta)\r\n",
        "print(y_hat)\r\n",
        "if y_hat > 0.5:\r\n",
        "    print('Positive sentiment')\r\n",
        "else: \r\n",
        "    print('Negative sentiment')\r\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading\n",
            "Downloaded 1 tweets\n",
            "Downloaded 1 tweets , saved to newFile.txt\n",
            " The tweet is: \n",
            "b'RT @vegsource: I am afraid COVID-19 has exposed the vaccine business for what it is: greed-driven, profit-driven, dishonest pusher of unsaf\\xe2\\x80\\xa6'\n",
            "\n",
            "B'RT I AM AFRAID COVID-19 HAS EXPOSED THE VACCINE BUSINESS FOR WHAT IT IS: GREED-DRIVEN, PROFIT-DRIVEN, DISHONEST PUSHER OF UNSAF\\XE2\\X80\\XA6'\n",
            "[[0.50785264]]\n",
            "Positive sentiment\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6tykWu_fAOS",
        "outputId": "be8bbf83-484e-4098-b7ff-8f245c7af930"
      },
      "source": [
        "def logistic_classifier():\r\n",
        "  my_tweet =  processing()\r\n",
        "  print(my_tweet)\r\n",
        "  y_hat = predict_tweet(my_tweet, freqs, theta)\r\n",
        "  print(y_hat)\r\n",
        "  if y_hat > 0.5:\r\n",
        "      print('Positive sentiment')\r\n",
        "  else: \r\n",
        "      print('Negative sentiment')\r\n",
        "\r\n",
        "print(\"CLASSIFICATION USING LOGISTIC REGRESSION:\")\r\n",
        "logistic_classifier()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CLASSIFICATION USING LOGISTIC REGRESSION:\n",
            "downloading\n",
            "no more tweets found\n",
            "Downloaded 0 tweets , saved to newFile.txt\n",
            " The tweet is: \n",
            "\n",
            "\n",
            "[[0.50004199]]\n",
            "Positive sentiment\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fitnK5HPy97"
      },
      "source": [
        "# **MAIN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvAQaAGF3yc1"
      },
      "source": [
        "#################\r\n",
        "# extract tweets:\r\n",
        "# extraction()\r\n",
        "\r\n",
        "# preprocessing:\r\n",
        "# processing()\r\n",
        "\r\n",
        "# naive bayes classification\r\n",
        "# naive_classifer()\r\n",
        "\r\n",
        "# logistic regression classifier\r\n",
        "# logistic_classifier()"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfK2s-2rP336",
        "outputId": "339df84a-a349-478c-dce9-26d977048b71"
      },
      "source": [
        "import time\r\n",
        "\r\n",
        "def calling():\r\n",
        "    for counter in range(2):\r\n",
        "        # extraction()\r\n",
        "        # processing()\r\n",
        "        naive_classifier()\r\n",
        "        print(\"======================================================\")\r\n",
        "        logistic_classifier()\r\n",
        "        print(\"======================================================\")\r\n",
        "        print(\"======================================================\")\r\n",
        "        time.sleep(20)\r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    calling()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading\n",
            "Downloaded 1 tweets\n",
            "Downloaded 1 tweets , saved to newFile.txt\n",
            " The tweet is: \n",
            "b'RT @CNN: A growing group of people who get sick with Covid-19 never fully recover. In support groups, they sometimes refer to themselves as\\xe2\\x80\\xa6'\n",
            "\n",
            "CLASSIFICATION USING NAIVE BAYES\n",
            "[0]\n",
            "======================================================\n",
            "downloading\n",
            "Downloaded 1 tweets\n",
            "Downloaded 1 tweets , saved to newFile.txt\n",
            " The tweet is: \n",
            "b'RT @CNN: A growing group of people who get sick with Covid-19 never fully recover. In support groups, they sometimes refer to themselves as\\xe2\\x80\\xa6'\n",
            "\n",
            "B'RT A GROWING GROUP OF PEOPLE WHO GET SICK WITH COVID-19 NEVER FULLY RECOVER. IN SUPPORT GROUPS, THEY SOMETIMES REFER TO THEMSELVES AS\\XE2\\X80\\XA6'\n",
            "[[0.52200796]]\n",
            "Positive sentiment\n",
            "======================================================\n",
            "======================================================\n",
            "downloading\n",
            "Downloaded 1 tweets\n",
            "Downloaded 1 tweets , saved to newFile.txt\n",
            " The tweet is: \n",
            "b'RT @_ThomasRoyalty: Due to COVID-19, my company reduced our hours to 20 hours a week. I\\xe2\\x80\\x99m a little short on cash for bills and groceries, i\\xe2\\x80\\xa6'\n",
            "\n",
            "CLASSIFICATION USING NAIVE BAYES\n",
            "[0]\n",
            "======================================================\n",
            "downloading\n",
            "Downloaded 1 tweets\n",
            "Downloaded 1 tweets , saved to newFile.txt\n",
            " The tweet is: \n",
            "b'RT @_ThomasRoyalty: Due to COVID-19, my company reduced our hours to 20 hours a week. I\\xe2\\x80\\x99m a little short on cash for bills and groceries, i\\xe2\\x80\\xa6'\n",
            "\n",
            "B'RT DUE TO COVID-19, MY COMPANY REDUCED OUR HOURS TO 20 HOURS A WEEK. I\\XE2\\X80\\X99M A LITTLE SHORT ON CASH FOR BILLS AND GROCERIES, I\\XE2\\X80\\XA6'\n",
            "[[0.5110303]]\n",
            "Positive sentiment\n",
            "======================================================\n",
            "======================================================\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}